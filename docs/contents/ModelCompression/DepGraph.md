# DepGraph: Towards Any Structural Pruning



**作者：** Gongfan Fang Xinyin Ma Mingli Song Michael Bi Mi Xinchao Wang

**发表刊物/会议：** CVPR

**发表年份：** 2023

**论文地址：** https://arxiv.org/abs/2301.12900

**代码地址：** https://github.com/VainF/Torch-Pruning


## 内容概要

结构修剪通过从神经网络中去除结构分组参数来实现模型加速。然而，参数分组模式在不同的模型中差异很大，它依赖于手动设计分组方案，使得特定体系结构的修剪器无法推广到新的体系结构。在这项工作中，研究了一个极具挑战性但很少探索的任务，即任何结构修剪，以解决任意架构(如cnn, rnn, gnn和transformer)的一般结构修剪。实现这一目标最突出的障碍在于结构耦合，它不仅迫使不同的层同时被修剪，而且希望所有被删除的参数始终不重要，从而避免修剪后出现结构问题和显著的性能下降。为了解决这一问题，本文提出了一种通用的全自动方法——依赖图(DepGraph)，该方法显式地对层与层之间的依赖关系进行建模，并对耦合参数进行综合分组以进行剪枝。在这项工作中，本文在几种架构和任务上广泛评估了所提的方法，包括用于图像的ResNe(X)t、DenseNet、MobileNet和Vision transformer，用于图形的GAT，用于3D点云的DGCNN，以及用于语言的LSTM，并证明，即使使用简单的基于范式的标准，所提出的方法也始终产生令人满意的性能。


## 主要解决问题/应用

- 如何实现对神经网络中的任何结构进行剪枝

- 参数分组是结构化剪枝算法落地的一个难题。深度神经网络是建立在卷积、归一化或激活等大量基本模块之上的，而这些模块，无论是否参数化，都是通过复杂的连接内在耦合的，裁剪具有耦合和复杂内部结构的现代深度神经网络是一项挑战性任务。


## 主要使用方法/模型

DepGraph的主要使用方法是构建一个依赖图来表示神经网络中的结构关系。这个依赖图可以捕捉网络中各个结构之间的依赖关系，从而为剪枝策略提供指导。DepGraph的核心思想是将剪枝问题转化为一个图优化问题，通过求解这个优化问题来确定剪枝策略。

DepGraph的模型包括以下几个关键组件：

- 依赖图构建：首先，根据神经网络的结构构建一个依赖图。这个依赖图表示网络中各个结构之间的依赖关系，例如卷积层、激活层、池化层等。

- 剪枝策略生成：利用依赖图来生成剪枝策略。这个策略可以指导用户选择要剪枝的结构，从而实现对神经网络的定制化压缩。

- 剪枝策略优化：通过求解图优化问题来确定最终的剪枝策略。这个优化问题可以确保剪枝后的模型结构保持相对完整，便于硬件加速计算。


## 主要实验手段/数据集

实验手段：

- 模型选择：DepGraph在多种类型的神经网络（如卷积神经网络（CNN）和循环神经网络（RNN））上进行实验，以验证其在不同网络结构中的有效性。

- 剪枝策略比较：DepGraph与其他剪枝方法（如非结构化剪枝和结构化剪枝）进行比较，以评估其在保持模型性能的同时实现模型压缩的能力。

- 剪枝效果评估：通过计算模型的参数量、计算量和精度等指标，评估DepGraph在不同剪枝策略下的剪枝效果。

数据集：

- DepGraph在多个数据集上进行实验，包括：

- CIFAR-10：一个包含10个类别的图像分类数据集，包含60,000张32x32像素的彩色图像。

- ImageNet：一个大型图像分类数据集，包含1,000个类别，超过1,000,000张图像。

- Penn Treebank：一个用于自然语言处理任务的文本数据集，包含超过1,000,000个单词。

## 创造性思考

- 提出了一种名为DepGraph的结构化剪枝方法，该方法可以灵活地对神经网络中的任何结构进行剪枝。
- DepGraph通过构建一个依赖图来表示神经网络中的结构关系，然后利用这个依赖图来确定剪枝策略。这种方法可以应用于各种类型的神经网络，通过DepGraph，用户可以灵活地选择要剪枝的结构，从而实现对神经网络的定制化压缩。这为神经网络剪枝提供了一种新的思路和方法。

## 批判式思考

- 实验范围有限：文章中仅在部分数据集和网络结构上进行了实验，可能无法充分验证DepGraph在所有场景下的通用性和有效性。

- 剪枝策略选择：虽然DepGraph提供了一种灵活的剪枝策略选择方法，但在实际应用中，用户可能需要根据具体任务和需求进行调整和优化。

- 计算复杂度：构建依赖图和求解图优化问题可能会增加计算复杂度，这可能对实时应用和大规模神经网络剪枝产生影响。

## 讨论 


1. 层内依赖的处理方式是什么样的？

    算法会分析神经网络中的每个层，找出层内各个结构之间的连接和依赖关系。然后，将这些关系表示为依赖图中的节点和边。通过这种方式，算法可以捕捉到层内依赖关系，并在剪枝过程中充分利用这些信息来确定剪枝策略。

2. 怎么理解Batch Normalization的输入输出则存在简单的层内依赖？

    Batch Normalization通过对输入数据的均值和方差进行归一化处理，使得输出数据的均值为0，方差为1。这有助于减少内部协变量偏移（Internal Covariate Shift），从而加速神经网络的训练过程。
    
    在Batch Normalization中，输入输出之间的简单层内依赖关系体现在以下几点：

   - 均值和方差计算：Batch Normalization计算输入数据的均值和方差，这些统计量是输入数据的函数，因此输入数据和输出数据之间存在简单的依赖关系。

   - 归一化处理：Batch Normalization对输入数据进行归一化处理，使得输出数据的均值为0，方差为1。这使得输出数据的分布更加稳定，从而有助于提高模型性能。

   - 参数更新：Batch Normalization引入了可学习的参数（如缩放因子和偏移因子），这些参数可以根据输入数据的变化进行更新。这使得输入输出之间存在简单的依赖关系，有助于模型适应不同的输入数据分布。

3. 结构化裁剪和非结构化裁剪的区别是什么？
    - 结构修剪通过物理去除分组参数来改变神经网络的结构，去除不重要的神经元，相应地，被剪除的神经元和其他神经元之间的连接在计算时会被忽略
    - 非结构修剪在不改变网络结构的情况下对部分权值进行归零
    - 与非结构化修剪相比，结构化修剪不依赖于特定的人工智能加速器或软件来减少内存消耗和计算成本，从而在实践中找到更广泛的应用领域。从技术上讲，结构化剪枝按组剪枝权重（删除整个神经元、过滤器或卷积神经网络的通道）。非结构化剪枝不考虑剪枝权重之间的任何关系

4. group级别的pruning具体是怎么做的？

   - 权重矩阵分组：首先，将神经网络中的权重矩阵划分为多个组。每个组包含一定数量的权重。组的数量和每个组的大小可以根据实际需求进行调整。

   - 构建依赖图：根据神经网络的结构，构建一个依赖图来表示网络中各个结构之间的依赖关系。依赖图可以捕捉到组之间的连接和依赖关系。

   - 剪枝策略生成：利用依赖图来生成剪枝策略。这个策略可以指导用户选择要剪枝的组，从而实现对神经网络的定制化压缩。

   - 剪枝：根据剪枝策略对每个组进行剪枝。通常，我们会保留每个组中权重重要性最高的部分权重，并将其余权重设置为零。剪枝比例可以根据实际需求进行调整。

   - 重新训练：剪枝后，对模型进行重新训练，以补偿剪枝过程中可能带来的性能损失。重新训练可以使用原始的训练数据和标签，或者使用部分训练数据进行微调。




## 参考链接

- <https://cs.nju.edu.cn/wujx/paper/Pruning_Survey_MLA21.pdf>
- <https://zhuanlan.zhihu.com/p/619482727>